use genai_types::{
    messages::{Role as GenaiRole, StopReason},
    CompletionRequest, CompletionResponse, Message, MessageContent, ToolChoice, Usage,
};
use mcp_protocol::tool::Tool as McpTool;
use serde::{Deserialize, Serialize};

/// Represents an error from the Gemini API
#[derive(Debug, Serialize, Deserialize)]
pub enum GeminiError {
    /// Invalid request format
    InvalidRequest(String),

    /// API error response
    ApiError { status: u16, message: String },

    /// HTTP error
    HttpError(String),

    /// Invalid response format
    InvalidResponse(String),

    /// JSON serialization/deserialization error
    SerdeError(String),

    /// Unsupported feature
    UnsupportedFeature(String),

    /// Serialization error
    SerializationError(String),
}

impl From<serde_json::Error> for GeminiError {
    fn from(err: serde_json::Error) -> Self {
        GeminiError::SerdeError(err.to_string())
    }
}

/// Role in a conversation (user or model)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum Role {
    #[serde(rename = "user")]
    User,

    #[serde(rename = "model")]
    Model,

    #[serde(rename = "system")]
    System,
}

impl From<GenaiRole> for Role {
    fn from(role: GenaiRole) -> Self {
        match role {
            GenaiRole::User => Role::User,
            GenaiRole::Assistant => Role::Model,
            GenaiRole::System => Role::System,
        }
    }
}

impl From<Role> for GenaiRole {
    fn from(role: Role) -> Self {
        match role {
            Role::User => GenaiRole::User,
            Role::Model => GenaiRole::Assistant,
            Role::System => GenaiRole::System,
        }
    }
}

impl Default for Role {
    fn default() -> Self {
        Role::Model
    }
}

/// Function call issued by model
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FunctionCall {
    pub id: String,
    pub name: String,
    pub args: serde_json::Value,
}

/// Response from a function call
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FunctionResponse {
    pub id: String,
    pub name: String,
    pub response: serde_json::Value,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ContentPart {
    #[serde(skip_serializing_if = "Option::is_none")]
    thought: Option<bool>,
    #[serde(flatten)]
    pub data: PartData,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(untagged)]
pub enum PartData {
    Text { text: String },

    Other(OtherData),
}

/// Content part type for Gemini API
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(untagged)]
pub enum OtherData {
    /// Inline data (like images)
    InlineData {
        #[serde(rename = "mimeType")]
        mime_type: String,
        data: String,
    },

    /// Function call generated by model
    FunctionCall {
        #[serde(rename = "functionCall")]
        function_call: FunctionCall,
    },

    /// Response from function call
    FunctionResponse {
        #[serde(rename = "functionResponse")]
        function_response: FunctionResponse,
    },
}

impl TryFrom<MessageContent> for ContentPart {
    type Error = GeminiError;

    fn try_from(content: MessageContent) -> Result<Self, GeminiError> {
        match content {
            MessageContent::Text { text } => Ok(ContentPart {
                thought: None,
                data: PartData::Text { text },
            }),
            MessageContent::ToolUse { name, input, id } => Ok(ContentPart {
                thought: None,
                data: PartData::Other(OtherData::FunctionCall {
                    function_call: FunctionCall {
                        id,
                        name,
                        args: input,
                    },
                }),
            }),
            MessageContent::ToolResult { .. } => Err(GeminiError::UnsupportedFeature(
                "Tool results are not directly supported in Gemini requests".to_string(),
            )),
        }
    }
}

impl TryFrom<ContentPart> for MessageContent {
    type Error = GeminiError;

    fn try_from(content: ContentPart) -> Result<Self, GeminiError> {
        match content.data {
            PartData::Text { text, .. } => Ok(MessageContent::Text { text }),
            PartData::Other(OtherData::FunctionCall { function_call, .. }) => {
                Ok(MessageContent::ToolUse {
                    id: function_call.id,
                    name: function_call.name,
                    input: function_call.args,
                })
            }
            PartData::Other(OtherData::FunctionResponse {
                function_response, ..
            }) => Ok(MessageContent::ToolResult {
                tool_use_id: function_response.id,
                content: vec![mcp_protocol::tool::ToolContent::Text {
                    text: serde_json::to_string(&function_response.response)
                        .unwrap_or_else(|_| "{}".to_string()),
                }],
                is_error: None,
            }),
            PartData::Other(OtherData::InlineData {
                mime_type, data, ..
            }) => {
                // Only support images for now, as they're the most common media type
                if mime_type.starts_with("image/") {
                    Err(GeminiError::UnsupportedFeature(
                        "Image conversion not implemented yet".to_string(),
                    ))
                } else {
                    // For other media types, convert to text for now
                    Ok(MessageContent::Text {
                        text: format!("[Media content of type: {} {}]", mime_type, data),
                    })
                }
            }
        }
    }
}

/// Content from Gemini API
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Content {
    pub parts: Vec<ContentPart>,
    #[serde(default)]
    pub role: Role,
}

impl TryFrom<Message> for Content {
    type Error = GeminiError;
    fn try_from(message: Message) -> Result<Self, Self::Error> {
        Ok(Content {
            role: message.role.into(),
            parts: message
                .content
                .into_iter()
                .map(|part| {
                    part.try_into().map_err(|e| {
                        GeminiError::SerializationError(format!(
                            "Failed to convert message part: {:?}",
                            e
                        ))
                    })
                })
                .collect::<Result<Vec<ContentPart>, GeminiError>>()
                .map_err(|e| GeminiError::SerializationError(format!("{:?}", e)))?,
        })
    }
}

impl TryFrom<Content> for Message {
    type Error = GeminiError;
    fn try_from(content: Content) -> Result<Self, Self::Error> {
        Ok(Message {
            role: content.role.into(),
            content: content
                .parts
                .into_iter()
                .map(|part| {
                    part.try_into().map_err(|e| {
                        GeminiError::SerializationError(format!(
                            "Failed to convert message part: {:?}",
                            e
                        ))
                    })
                })
                .collect::<Result<Vec<MessageContent>, GeminiError>>()
                .map_err(|e| GeminiError::SerializationError(format!("{:?}", e)))?,
        })
    }
}

/// Generation config for Gemini API
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct GenerationConfig {
    #[serde(skip_serializing_if = "Option::is_none")]
    pub temperature: Option<f32>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub max_output_tokens: Option<u32>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub top_p: Option<f32>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub top_k: Option<u32>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub stop_sequences: Option<Vec<String>>,
}

/// Function declaration for Gemini tools
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FunctionDeclaration {
    pub name: String,
    pub description: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub parameters: Option<serde_json::Value>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub response: Option<serde_json::Value>,
}

/// Tool type for Gemini API
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Tool {
    #[serde(skip_serializing_if = "Option::is_none")]
    pub function_declarations: Option<Vec<FunctionDeclaration>>,
}

impl TryFrom<McpTool> for FunctionDeclaration {
    type Error = GeminiError;

    fn try_from(tool: McpTool) -> Result<Self, Self::Error> {
        Ok(FunctionDeclaration {
            name: tool.name,
            description: tool.description.unwrap_or_default(),
            parameters: Some(tool.input_schema),
            response: None, // Response schema is not typically provided in MCP
        })
    }
}

impl TryFrom<FunctionDeclaration> for McpTool {
    type Error = GeminiError;

    fn try_from(decl: FunctionDeclaration) -> Result<Self, Self::Error> {
        Ok(McpTool {
            name: decl.name,
            description: Some(decl.description),
            input_schema: decl.parameters.unwrap_or(serde_json::json!({})),
            annotations: None,
        })
    }
}

/// Function calling mode
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum FunctionCallingMode {
    #[serde(rename = "AUTO")]
    Auto,
    #[serde(rename = "ANY")]
    Any,
    #[serde(rename = "NONE")]
    None,
}

/// Function calling configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FunctionCallingConfig {
    #[serde(skip_serializing_if = "Option::is_none")]
    pub mode: Option<FunctionCallingMode>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub allowed_function_names: Option<Vec<String>>,
}

/// Tool configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ToolConfig {
    #[serde(skip_serializing_if = "Option::is_none")]
    pub function_calling_config: Option<FunctionCallingConfig>,
}

/// Request to generate content
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct GenerateContentRequest {
    pub model: String,

    pub contents: Vec<Content>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub generation_config: Option<GenerationConfig>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub system_instruction: Option<Content>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub tools: Option<Vec<Tool>>,

    #[serde(skip_serializing_if = "Option::is_none")]
    pub tool_config: Option<ToolConfig>,
}

impl TryFrom<CompletionRequest> for GenerateContentRequest {
    type Error = GeminiError;
    fn try_from(request: CompletionRequest) -> Result<Self, Self::Error> {
        // Handle system instruction
        let system_instruction = if request.system.is_some() {
            Some(request.system.as_ref().map(|s| Content {
                role: Role::System,
                parts: vec![ContentPart {
                    thought: None,
                    data: PartData::Text { text: s.clone() },
                }],
            }))
        } else {
            None
        };

        // Create generation config
        let generation_config = Some(GenerationConfig {
            temperature: request.temperature,
            max_output_tokens: Some(request.max_tokens),
            top_p: None,
            top_k: None,
            stop_sequences: None,
        });

        // Handle tools
        let tools = if let Some(tools) = request.tools {
            if !tools.is_empty() {
                let function_declarations = tools
                    .into_iter()
                    .map(|tool| tool.try_into())
                    .collect::<Result<Vec<FunctionDeclaration>, GeminiError>>()?;

                Some(vec![Tool {
                    function_declarations: Some(function_declarations),
                }])
            } else {
                None
            }
        } else {
            None
        };

        // Configure tool usage
        let tool_config = if tools.is_some() {
            let mode = match request.tool_choice {
                Some(ToolChoice::Auto) => FunctionCallingMode::Auto,
                Some(ToolChoice::Any) => FunctionCallingMode::Any,
                Some(ToolChoice::None) => FunctionCallingMode::None,
                Some(ToolChoice::Tool { .. }) => FunctionCallingMode::Any, // Specific tool = ANY mode
                None => FunctionCallingMode::Auto,                         // Default to auto
            };

            // If a specific tool was requested, set it in allowed_function_names
            let allowed_function_names = match &request.tool_choice {
                Some(ToolChoice::Tool { name }) => Some(vec![name.clone()]),
                _ => None,
            };

            Some(ToolConfig {
                function_calling_config: Some(FunctionCallingConfig {
                    mode: Some(mode),
                    allowed_function_names,
                }),
            })
        } else {
            None
        };

        Ok(GenerateContentRequest {
            model: request.model,
            contents: request
                .messages
                .into_iter()
                .map(|msg| msg.try_into())
                .collect::<Result<Vec<Content>, GeminiError>>()
                .map_err(|e| {
                    GeminiError::SerializationError(format!("Failed to convert message: {:?}", e))
                })?,
            generation_config,
            system_instruction: system_instruction.flatten(),
            tools,
            tool_config,
        })
    }
}

/// Usage metrics
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct UsageMetadata {
    pub prompt_token_count: u32,
    pub candidates_token_count: u32,
    pub total_token_count: u32,
}

impl TryFrom<UsageMetadata> for Usage {
    type Error = GeminiError;

    fn try_from(usage: UsageMetadata) -> Result<Self, Self::Error> {
        Ok(genai_types::Usage {
            input_tokens: usage.prompt_token_count,
            output_tokens: usage.candidates_token_count,
        })
    }
}

/// Candidate response from Gemini API
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct Candidate {
    pub content: Content,
    pub finish_reason: FinishReason,
    #[serde(default)]
    pub index: u32,
    #[serde(default)]
    pub safety_ratings: Vec<SafetyRating>,
}

/// Finish reason for the a candidate
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum FinishReason {
    #[serde(rename = "FINISH_REASON_UNSPECIFIED")]
    FinishReasonUnspecified,

    #[serde(rename = "STOP")]
    Stop,

    #[serde(rename = "MAX_TOKENS")]
    MaxTokens,

    #[serde(rename = "SAFETY")]
    Safety,

    #[serde(rename = "RECITATION")]
    Recitation,

    #[serde(rename = "LANGUAGE")]
    Language,

    #[serde(rename = "OTHER")]
    Other,

    #[serde(rename = "BLOCKLIST")]
    Blocklist,

    #[serde(rename = "PROHIBITED_CONTENT")]
    ProhibitedContent,

    #[serde(rename = "SPII")]
    Spii,

    #[serde(rename = "MALFORMED_FUNCTION_CALL")]
    MalformedFunctionCall,

    #[serde(rename = "IMAGE_SAFETY")]
    ImageSafety,
}

impl From<FinishReason> for StopReason {
    fn from(reason: FinishReason) -> Self {
        match reason {
            FinishReason::FinishReasonUnspecified => StopReason::EndTurn,
            FinishReason::Stop => StopReason::EndTurn,
            FinishReason::MaxTokens => StopReason::MaxTokens,
            _ => StopReason::Other(
                serde_json::to_string(&reason).unwrap_or_else(|_| "Unknown".to_string()),
            ),
        }
    }
}

/// Safety rating from Gemini API
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SafetyRating {
    pub category: String,
    pub probability: String,
}

/// Response from Gemini API
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct GenerateContentResponse {
    pub candidates: Vec<Candidate>,
    pub prompt_feedback: Option<PromptFeedback>,
    pub usage_metadata: Option<UsageMetadata>,
    pub model_version: String,
}

impl TryFrom<GenerateContentResponse> for CompletionResponse {
    type Error = GeminiError;

    fn try_from(response: GenerateContentResponse) -> Result<Self, Self::Error> {
        // We are only interested in the first candidate for now
        if response.candidates.is_empty() {
            return Err(GeminiError::InvalidResponse(
                "No candidates in response".to_string(),
            ));
        }

        let candidate = response.candidates[0].clone();

        // Convert all parts in the candidate to MessageContent
        let content_parts = candidate
            .content
            .parts
            .iter()
            .map(|part| (*part).clone().try_into())
            .collect::<Result<Vec<MessageContent>, GeminiError>>()?;

        let usage = match response.usage_metadata {
            Some(usage) => Usage {
                input_tokens: usage.prompt_token_count,
                output_tokens: usage.candidates_token_count,
            },
            None => Usage {
                input_tokens: 0,
                output_tokens: 0,
            },
        };

        // Check if the response contains a function call
        let has_function_call = content_parts
            .iter()
            .any(|part| matches!(part, MessageContent::ToolUse { .. }));

        // Set stop reason to ToolUse if function call is present
        let stop_reason = if has_function_call {
            StopReason::ToolUse
        } else {
            candidate.finish_reason.into()
        };

        Ok(CompletionResponse {
            content: content_parts,
            id: candidate.index.to_string(),
            model: response.model_version,
            role: candidate.content.role.into(),
            stop_reason,
            stop_sequence: None,
            message_type: "gemini".to_string(),
            usage,
        })
    }
}

/// Feedback on prompt
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PromptFeedback {
    pub safety_ratings: Vec<SafetyRating>,
}

/// Request type for the Google Proxy
#[derive(Debug, Serialize, Deserialize)]
pub enum GeminiRequest {
    GenerateContent {
        request: GenerateContentRequest,
        model: String,
        stream: bool,
    },
    ListModels,
}

/// Response from Google Proxy
#[derive(Debug, Serialize, Deserialize)]
pub enum GeminiResponse {
    Content { content: GenerateContentResponse },
    ListModels { models: Vec<ModelInfo> },
    Error { error: String },
}

/// Model information
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelInfo {
    pub id: String,
    pub display_name: String,
    pub description: Option<String>,
    pub input_token_limit: u32,
    pub output_token_limit: u32,
    pub supported_generation_methods: Vec<String>,
    pub temperature_range: Option<(f32, f32)>,
    pub top_p_range: Option<(f32, f32)>,
    pub top_k_range: Option<(u32, u32)>,
}

impl From<ModelInfo> for genai_types::ModelInfo {
    fn from(model: ModelInfo) -> Self {
        genai_types::ModelInfo {
            id: model.id,
            display_name: model.display_name,
            provider: "google".to_string(),
            max_tokens: model.output_token_limit,
            pricing: None,
        }
    }
}

impl ModelInfo {
    pub fn get_default_models() -> Vec<ModelInfo> {
        vec![
            ModelInfo {
                id: "gemini-2.0-flash".to_string(),
                display_name: "Gemini 2.0 Flash".to_string(),
                description: Some(
                    "Optimized for speed, versatile on a broad range of tasks".to_string(),
                ),
                input_token_limit: 32_000,
                output_token_limit: 8_000,
                supported_generation_methods: vec![
                    "generateContent".to_string(),
                    "streamGenerateContent".to_string(),
                ],
                temperature_range: Some((0.0, 2.0)),
                top_p_range: Some((0.0, 1.0)),
                top_k_range: Some((1, 40)),
            },
            ModelInfo {
                id: "gemini-2.0-pro".to_string(),
                display_name: "Gemini 2.0 Pro".to_string(),
                description: Some(
                    "High-quality model with strong reasoning across a variety of tasks"
                        .to_string(),
                ),
                input_token_limit: 32_000,
                output_token_limit: 16_000,
                supported_generation_methods: vec![
                    "generateContent".to_string(),
                    "streamGenerateContent".to_string(),
                ],
                temperature_range: Some((0.0, 2.0)),
                top_p_range: Some((0.0, 1.0)),
                top_k_range: Some((1, 40)),
            },
        ]
    }
}
